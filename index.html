<!DOCTYPE html>
<html lang="de">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="css/style.css">
  <title>GVT - EA10 - Kim Feller</title>
  <script src="https://cdn.jsdelivr.net/gh/karpathy/tsnejs/tsne.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/gl-matrix/2.4.0/gl-matrix.js"></script>
</head>
<body>
<h1>EA10 - Seeds Daten in 3D</h1>
<h2>Graphical Visualisation Technologies</h2>
<p>Kim Lara Feller, Technische Hochschule Lübeck, Matrikelnummer 331177</p>
<p><b>Hinweise und Referenzen</b></p>
<p> Beim Laden der Seite wird das bereits mit dem t-SNE Algorithmus optimierte Ergebnis anhand der gespeicherten
  dimensionsreduzierten Daten geladen. Hierfür wurde der Datensatz von sieben vorhandenen Dimensionen auf drei reduziert.
  Außerdem wurde das Klassifizierungsmerkmal der Getreidesorte farblich entsprechend eingefärbt: Grün (1), pink (2) und blau (3).
  Der Datensatz enthält 210 Punkte und ist damit eher als kleiner Datensatz zu betrachten, weshalb sich eine Perplexity zwischen 5-50 anbietet.
  Eine geringere Perplexity fördert lokale Clusterbildung, also macht detaillierte Unterteilungen sichtbar. Eine höhere Perplexity
  stellt dementsprechend besser die globalen Strukturen dar. Ich habe für die beispielhafte Visualisierung eine moderate Perplexity von 35
  gewählt, um sowohl lokale als auch globale Strukturen zu zeigen. Eine höhere Perplexity (z.B. >50) würde zudem dazu führen, dass das Ergebnis "glatt"
  wird, was eine Interpretierbarkeit in 3D erschwert.
  Als Lernrate habe ich 150 gewählt. t-SNE ist grundsätzlich robust gegenüber höheren Lernraten und bei einer 3D-Reduktion werden mehr Iterationsschritte benötigt,
  die mit einer zu niedrigen Lernrate ineffizient sein könnten. Ich habe aber auch mit niedrigeren und höheren Lernraten herumexperimentiert und mit entsprechenden
  Iterationen vergleichbare Ergebnisse erzielen können. Das initial gezeigte Ergebnis ist nach 126 Iterationen.<br><br>
  <b><u>Kamera und Perspektive sind über folgende Tasten einstellbar</u></b></p>
<ul>
  <li><b>X</b> Datenvolumen wird entlang der X-Achse rotiert</li>
  <li><b>Y</b> Datenvolumen wird entlang der Y-Achse rotiert</li>
  <li><b>Z</b> Datenvolumen wird entlang der Z-Achse rotiert</li>
  <li><b>B</b> und <b>N</b> Hinein- bzw. Hinauszoomen</li>
  <li><b>W, A, S, D</b> Kamera wird nach oben, links, unten oder rechts verschoben</li>
  <li><b>P</b> Ansicht wird zurückgesetzt</li>
</ul>
  <p>Der <a target="_blank" href="https://archive.ics.uci.edu/dataset/236/seeds">zugrundeliegende Datensatz</a>  kann mit den folgenden Optionen manipuliert werden:</p><br>
  <b><u>Button unterhalb des Canvas</u></b><br>
  <ul>
    <li><b>Start t-SNE</b> Der t-SNE wird auf den ursprünglichen Datensatz neu gestartet</li>
    <li><b>Iteration +1 </b> Der t-SNE Algorithmus wird schrittweise (+1) inkrementiert</li>
    <li><b>Start/Stop Auto Iteration</b> Der t-SNE Algorithmus wird automatisch bis zum Erneuten drücken des Button inkrementiert </li>
    <li><b>Speichern</b> Der Datensatz der aktuellen Visualisierung wird als CSV-Datei abgespeichert und dem Client als Download bereitgestellt</li>
  </ul>
  <p>Die Visualisierung, sowie der Iterations-Zähler unterhalb der Button werden entsprechend der Interaktion aktualisiert. Wird die automatische Inkrementierung gestoppt,
kann außerdem noch manuell schrittweise die Iteration erhöht werden. Dies ermöglicht ein effizientes und konkretes Darstellen des t-SNE<br><br>
<canvas id="glCanvas" width="800" height="600"></canvas>
<div class="controls">
  <button id="restartBtn">Start t-SNE</button>
  <button id="stepBtn">Iteration +1</button>
  <button id="autoIterateBtn">Start/Stop Auto Iteration</button>
  <button id="saveBtn">Speichern</button>
</div>
<div id="iterationDisplay">Aktuelle Iteration: <span id="iterationCounter">0</span></div>
<script>
  document.addEventListener("DOMContentLoaded", () => {
    const canvas = document.getElementById("glCanvas");
    let gl = canvas.getContext("webgl");

    if (!gl) {
      alert("WebGL not supported.");
      gl = canvas.getContext("experimental-webgl");
    }
    if (!gl) {
      alert("Your browser does not support WebGL");
    }

    gl.clearColor(0.0, 0.0, 0.0, 1.0);
    gl.clear(gl.COLOR_BUFFER_BIT);

    let tsne;
    let iterationCount = 0;
    let labels = [];
    let autoIterate = false;
    let autoIterateInterval;
    let allPoints = [];

    // CSV Datei einlesen
    async function loadCSV(filePath) {
      const response = await fetch(filePath);
      const data = await response.text();
      const rows = data.split("\n").filter(row => row.trim() !== "");
      return rows.map(row => {
        const cols = row.split(",");
        return {
          features: cols.slice(0, -1).map(Number),
          label: parseInt(cols[cols.length - 1])
        };
      });
    }

    // Normalisierung der Punkte für WebGL [-1, 1]
    function normalizePoints(points) {
      const flattened = points.flat();
      const min = Math.min(...flattened);
      const max = Math.max(...flattened);
      return points.map(point => point.map(coord => (2 * (coord - min) / (max - min)) - 1));
    }

    function initializeShaders(gl) {
      const vertCode = `
        attribute vec3 coordinates;
        attribute vec4 color;
        uniform mat4 modelViewMatrix;
        uniform mat4 projectionMatrix;
        varying vec4 vColor;
        void main(void) {
          gl_Position = projectionMatrix * modelViewMatrix * vec4(coordinates, 1.0);
          gl_PointSize = 5.0;
          vColor = color;
        }
      `;
      const fragCode = `
        precision mediump float;
        varying vec4 vColor;
        void main(void) {
          gl_FragColor = vColor;
        }
      `;

      const vertShader = gl.createShader(gl.VERTEX_SHADER);
      gl.shaderSource(vertShader, vertCode);
      gl.compileShader(vertShader);
      if (!gl.getShaderParameter(vertShader, gl.COMPILE_STATUS)) {
        console.error("Vertex Shader Error:", gl.getShaderInfoLog(vertShader));
      }

      const fragShader = gl.createShader(gl.FRAGMENT_SHADER);
      gl.shaderSource(fragShader, fragCode);
      gl.compileShader(fragShader);
      if (!gl.getShaderParameter(fragShader, gl.COMPILE_STATUS)) {
        console.error("Fragment Shader Error:", gl.getShaderInfoLog(fragShader));
      }

      const shaderProgram = gl.createProgram();
      gl.attachShader(shaderProgram, vertShader);
      gl.attachShader(shaderProgram, fragShader);
      gl.linkProgram(shaderProgram);
      if (!gl.getProgramParameter(shaderProgram, gl.LINK_STATUS)) {
        console.error("Shader Program Link Error:", gl.getProgramInfoLog(shaderProgram));
      }
      gl.useProgram(shaderProgram);

      return shaderProgram;
    }

    let shaderProgram;

    // Farben für die Klassifizierung
    const colorPalette = {
      1: [0.0, 1.0, 0.0], // Neongrün
      2: [1.0, 0.0, 1.0], // Neonpink
      3: [0.0, 0.5, 1.0], // Hellblau
    };

    // Punkte zeichnen (in 3D)
    function drawPoints(points) {
      gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

      const vertices = [];
      const colors = [];

      points.forEach((point, idx) => {
        vertices.push(point[0], point[1], point[2]);
        const color = colorPalette[labels[idx]] || [1.0, 1.0, 1.0];
        colors.push(...color);
      });

      const vertexBuffer = gl.createBuffer();
      gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer);
      gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(vertices), gl.STATIC_DRAW);

      const colorBuffer = gl.createBuffer();
      gl.bindBuffer(gl.ARRAY_BUFFER, colorBuffer);
      gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(colors), gl.STATIC_DRAW);

      const coord = gl.getAttribLocation(shaderProgram, "coordinates");
      gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer);
      gl.vertexAttribPointer(coord, 3, gl.FLOAT, false, 0, 0);
      gl.enableVertexAttribArray(coord);

      const color = gl.getAttribLocation(shaderProgram, "color");
      gl.bindBuffer(gl.ARRAY_BUFFER, colorBuffer);
      gl.vertexAttribPointer(color, 3, gl.FLOAT, false, 0, 0);
      gl.enableVertexAttribArray(color);

      // 3D Perspektive und Ansicht mit Rotation bzw. Zoom
      const modelViewMatrix = mat4.create();
      mat4.lookAt(modelViewMatrix, [cameraPosX, cameraPosY, cameraZoom], [0, 0, 0], [0, 1, 0]);  // Kameraposition

      // Rotation entsprechend der Interaktion (Tasteneingabe X,Y,Z)
      mat4.rotateX(modelViewMatrix, modelViewMatrix, rotationX);
      mat4.rotateY(modelViewMatrix, modelViewMatrix, rotationY);
      mat4.rotateZ(modelViewMatrix, modelViewMatrix, rotationZ);

      const projectionMatrix = mat4.create();
      mat4.perspective(projectionMatrix, Math.PI / 4, canvas.width / canvas.height, 0.1, 100);

      const modelViewLoc = gl.getUniformLocation(shaderProgram, "modelViewMatrix");
      const projectionLoc = gl.getUniformLocation(shaderProgram, "projectionMatrix");

      gl.uniformMatrix4fv(modelViewLoc, false, modelViewMatrix);
      gl.uniformMatrix4fv(projectionLoc, false, projectionMatrix);

      gl.viewport(0, 0, canvas.width, canvas.height);
      gl.drawArrays(gl.POINTS, 0, vertices.length / 3);
    }

    // Ein Iterationsdurchlauf des t-SNE
    function stepTSNE() {
      if (tsne) {
        tsne.step();
        iterationCount++;
        document.getElementById("iterationCounter").textContent = iterationCount;

        const result = tsne.getSolution();
        const normalizedResult = normalizePoints(result);
        allPoints = normalizedResult;  // Ergebnisse zwischenspeichern
        drawPoints(allPoints);  // Punkte neu zeichnen/aktualisieren
      }
    }

    // Starten und stoppen der automatischen Iteration
    function toggleAutoIteration() {
      if (autoIterate) {
        clearInterval(autoIterateInterval);
        autoIterate = false;
      } else {
        autoIterateInterval = setInterval(() => {
          stepTSNE();
        }, 100); // Iterationsgeschwindigkeit
        autoIterate = true;
      }
    }

    function updateIterationCounter() {
      document.getElementById("iterationCounter").textContent = iterationCount;
    }

    // Speichern der dimensionsreduzierten Daten als CSV-Datei
    function saveToFile() {
      if (tsne) {
        const result = tsne.getSolution();
        const csvContent = result.map((point, idx) => `${point.join(",")},${labels[idx]}`).join("\n");

        const blob = new Blob([csvContent], { type: "text/csv" });
        const url = URL.createObjectURL(blob);

        const a = document.createElement("a");
        a.href = url;
        a.download = "reduced_data.csv";
        a.click();

        URL.revokeObjectURL(url);
      }
    }

    // Laden und Anzeigen gespeicherter Daten
    async function loadSavedResult(filePath) {
      const response = await fetch(filePath);
      const data = await response.text();
      const rows = data.split("\n").filter(row => row.trim() !== "");
      const points = rows.map(row => row.split(",").slice(0, -1).map(Number));
      labels = rows.map(row => parseInt(row.split(",").pop()));
      const normalizedPoints = normalizePoints(points);
      allPoints = normalizedPoints;
      drawPoints(allPoints);
    }

    // Initialisieren des t-SNE auf gewünschten Datensatz (hier seeds.csv; entspricht https://archive.ics.uci.edu/dataset/236/seeds)
    async function initTSNE() {
      const data = await loadCSV("data/seeds.csv");

      const features = data.map(row => row.features);
      labels = data.map(row => row.label);

      tsne = new tsnejs.tSNE({
        dim: 3,
        perplexity: 35,  // Optimierte perplexity für bessere Klassifikation
        epsilon: 150,   // Lernrate
      });

      tsne.initDataRaw(features);
      iterationCount = 0;
      updateIterationCounter();

      const result = tsne.getSolution();
      const normalizedResult = normalizePoints(result);
      allPoints = normalizedResult;
      drawPoints(allPoints);
    }

    // Default: Kamera, Rotation und Zoom
    let rotationX = 0;
    let rotationY = 0;
    let rotationZ = 0;
    let cameraZoom = -3;
    let cameraPosX = 0;
    let cameraPosY = 0;

    // Interaktion Nutzereingaben
    document.addEventListener("keydown", (event) => {
      if (event.key === "x" || event.key === "X") {
        rotationX += 0.1;
      } else if (event.key === "y" || event.key === "Y") {
        rotationY += 0.1;
      } else if (event.key === "z" || event.key === "Z") {
        rotationZ += 0.1;
      } else if (event.key === "b" || event.key === "B") {
        cameraZoom += 0.1;
      } else if (event.key === "n" || event.key === "N") {
        cameraZoom -= 0.1;
      } else if (event.key === "w" || event.key === "W") {
        cameraPosY -= 0.1;
        allPoints.forEach(point => point[1] -= 0.1);
      } else if (event.key === "s" || event.key === "S") {
        cameraPosY += 0.1;
        allPoints.forEach(point => point[1] += 0.1);
      } else if (event.key === "d" || event.key === "D") {
        cameraPosX += 0.1;
        allPoints.forEach(point => point[0] += 0.1);
      } else if (event.key === "a" || event.key === "A") {
        cameraPosX -= 0.1;
        allPoints.forEach(point => point[0] -= 0.1);
      }  else if (event.key === "p" || event.key === "P") { // Ansicht zurücksetzen auf Default
        rotationX = 0;
        rotationY = 0;
        rotationZ = 0;
        cameraZoom = -3;
        cameraPosX = 0;
        cameraPosY = 0;
        allPoints = normalizePoints(tsne.getSolution());
        drawPoints(allPoints);
      }
      drawPoints(allPoints);
    });

    shaderProgram = initializeShaders(gl);

    // Button
    document.getElementById("restartBtn").addEventListener("click", initTSNE);
    document.getElementById("stepBtn").addEventListener("click", stepTSNE);
    document.getElementById("autoIterateBtn").addEventListener("click", toggleAutoIteration);
    document.getElementById("saveBtn").addEventListener("click", saveToFile);

    // Bei Laden der Seite wird gespeichertes Ergebnis angezeigt bis Button "Start t-SNE" betätigt wird
    loadSavedResult("data/reduced_data.csv");
  });
</script>
</body>
</html>
